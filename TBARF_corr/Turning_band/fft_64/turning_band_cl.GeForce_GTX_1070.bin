//
// Generated by NVIDIA NVVM Compiler
//
// Compiler Build ID: UNKNOWN
// Driver 
// Based on LLVM 3.4svn
//

.version 5.0
.target sm_61, texmode_independent
.address_size 64

	// .globl	make_reg_field1
// make_reg_field1_blocking$loc_vecs has been demoted
// make_reg_field1_blocking_unroll$loc_vecs has been demoted
// make_reg_field_outofcore_blocking$loc_vecs has been demoted
// make_irr_field_blocking$loc_vecs has been demoted
// make_irr_field_blocking_unroll$loc_vecs has been demoted

.entry make_reg_field1(
	.param .u32 make_reg_field1_param_0,
	.param .u32 make_reg_field1_param_1,
	.param .u32 make_reg_field1_param_2,
	.param .u32 make_reg_field1_param_3,
	.param .u32 make_reg_field1_param_4,
	.param .u64 .ptr .global .align 32 make_reg_field1_param_5,
	.param .u64 .ptr .global .align 8 make_reg_field1_param_6,
	.param .u64 .ptr .global .align 8 make_reg_field1_param_7,
	.param .f64 make_reg_field1_param_8
)
{
	.reg .pred 	%p<7>;
	.reg .b32 	%r<36>;
	.reg .f64 	%fd<36>;
	.reg .b64 	%rd<35>;


	ld.param.u32 	%r3, [make_reg_field1_param_0];
	ld.param.u32 	%r4, [make_reg_field1_param_2];
	ld.param.u32 	%r6, [make_reg_field1_param_3];
	ld.param.u32 	%r5, [make_reg_field1_param_4];
	ld.param.u64 	%rd13, [make_reg_field1_param_5];
	ld.param.u64 	%rd14, [make_reg_field1_param_6];
	ld.param.u64 	%rd15, [make_reg_field1_param_7];
	ld.param.f64 	%fd12, [make_reg_field1_param_8];
	mul.lo.s32 	%r7, %r6, %r4;
	cvt.s64.s32	%rd1, %r7;
	mov.u32 	%r8, %ctaid.x;
	mov.u32 	%r9, %ntid.x;
	mov.b32	%r10, %envreg3;
	mad.lo.s32 	%r11, %r8, %r9, %r10;
	mov.u32 	%r12, %tid.x;
	add.s32 	%r13, %r11, %r12;
	cvt.s64.s32	%rd2, %r13;
	or.b32  	%r14, %r13, %r7;
	cvt.s64.s32	%rd16, %r14;
	and.b64  	%rd17, %rd16, -4294967296;
	setp.eq.s64	%p1, %rd17, 0;
	@%p1 bra 	BB0_2;

	div.u64 	%rd32, %rd2, %rd1;
	rem.u64 	%rd33, %rd2, %rd1;
	bra.uni 	BB0_3;

BB0_2:
	cvt.u32.u64	%r15, %rd1;
	cvt.u32.u64	%r16, %rd2;
	div.u32 	%r17, %r16, %r15;
	rem.u32 	%r18, %r16, %r15;
	cvt.u64.u32	%rd32, %r17;
	cvt.u64.u32	%rd33, %r18;

BB0_3:
	cvt.s64.s32	%rd9, %r4;
	or.b64  	%rd18, %rd33, %rd9;
	and.b64  	%rd19, %rd18, -4294967296;
	setp.eq.s64	%p2, %rd19, 0;
	@%p2 bra 	BB0_5;

	div.u64 	%rd34, %rd33, %rd9;
	bra.uni 	BB0_6;

BB0_5:
	cvt.u32.u64	%r19, %rd9;
	cvt.u32.u64	%r20, %rd33;
	div.u32 	%r21, %r20, %r19;
	cvt.u64.u32	%rd34, %r21;

BB0_6:
	mov.f64 	%fd35, 0d0000000000000000;
	setp.lt.s32	%p3, %r3, 1;
	@%p3 bra 	BB0_11;

	cvt.u32.u64	%r23, %rd32;
	cvt.u32.u64	%r24, %rd34;
	mul.lo.s32 	%r25, %r24, %r4;
	cvt.u32.u64	%r26, %rd2;
	sub.s32 	%r27, %r26, %r25;
	cvt.u64.u32	%rd20, %r27;
	mul.lo.s64 	%rd21, %rd32, %rd1;
	sub.s64 	%rd22, %rd20, %rd21;
	cvt.u32.u64	%r28, %rd22;
	cvt.rn.f64.s32	%fd1, %r23;
	cvt.rn.f64.s32	%fd2, %r24;
	cvt.rn.f64.s32	%fd3, %r28;
	cvt.rn.f64.s32	%fd4, %r5;
	mov.f64 	%fd35, 0d0000000000000000;
	mov.u32 	%r35, 0;

BB0_8:
	mul.wide.s32 	%rd23, %r35, 32;
	add.s64 	%rd24, %rd13, %rd23;
	ld.global.v2.f64 	{%fd15, %fd16}, [%rd24+16];
	ld.global.v2.f64 	{%fd17, %fd18}, [%rd24];
	mul.f64 	%fd21, %fd2, %fd18;
	fma.rn.f64 	%fd22, %fd1, %fd17, %fd21;
	fma.rn.f64 	%fd24, %fd3, %fd15, %fd22;
	fma.rn.f64 	%fd26, %fd16, 0d0000000000000000, %fd24;
	mul.f64 	%fd27, %fd26, %fd12;
	neg.f64 	%fd34, %fd27;
	abs.f64 	%fd7, %fd34;
	setp.ge.f64	%p4, %fd7, 0d4330000000000000;
	@%p4 bra 	BB0_10;

	add.f64 	%fd28, %fd7, 0d3FE0000000000000;
	cvt.rzi.f64.f64	%fd29, %fd28;
	setp.lt.f64	%p5, %fd7, 0d3FE0000000000000;
	selp.f64	%fd30, 0d0000000000000000, %fd29, %p5;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r29, %temp}, %fd30;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r30}, %fd30;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r31}, %fd34;
	}
	and.b32  	%r32, %r31, -2147483648;
	or.b32  	%r33, %r30, %r32;
	mov.b64 	%fd34, {%r29, %r33};

BB0_10:
	fma.rn.f64 	%fd31, %fd4, 0d3FE0000000000000, %fd34;
	add.f64 	%fd32, %fd31, 0d3FF0000000000000;
	cvt.rzi.u64.f64	%rd25, %fd32;
	mul.lo.s32 	%r34, %r35, %r5;
	cvt.s64.s32	%rd26, %r34;
	add.s64 	%rd27, %rd25, %rd26;
	shl.b64 	%rd28, %rd27, 3;
	add.s64 	%rd29, %rd14, %rd28;
	ld.global.f64 	%fd33, [%rd29];
	add.f64 	%fd35, %fd35, %fd33;
	add.s32 	%r35, %r35, 1;
	setp.lt.s32	%p6, %r35, %r3;
	@%p6 bra 	BB0_8;

BB0_11:
	shl.b64 	%rd30, %rd2, 3;
	add.s64 	%rd31, %rd15, %rd30;
	st.global.f64 	[%rd31], %fd35;
	ret;
}

	// .globl	make_reg_field1_blocking
.entry make_reg_field1_blocking(
	.param .u32 make_reg_field1_blocking_param_0,
	.param .u32 make_reg_field1_blocking_param_1,
	.param .u32 make_reg_field1_blocking_param_2,
	.param .u32 make_reg_field1_blocking_param_3,
	.param .u32 make_reg_field1_blocking_param_4,
	.param .u64 .ptr .global .align 32 make_reg_field1_blocking_param_5,
	.param .u64 .ptr .global .align 8 make_reg_field1_blocking_param_6,
	.param .u64 .ptr .global .align 8 make_reg_field1_blocking_param_7,
	.param .f64 make_reg_field1_blocking_param_8
)
{
	.reg .pred 	%p<9>;
	.reg .b32 	%r<48>;
	.reg .f64 	%fd<46>;
	.reg .b64 	%rd<41>;
	// demoted variable
	.shared .align 32 .b8 make_reg_field1_blocking$loc_vecs[2048];

	ld.param.u32 	%r8, [make_reg_field1_blocking_param_0];
	ld.param.u32 	%r9, [make_reg_field1_blocking_param_2];
	ld.param.u32 	%r11, [make_reg_field1_blocking_param_3];
	ld.param.u32 	%r10, [make_reg_field1_blocking_param_4];
	ld.param.u64 	%rd13, [make_reg_field1_blocking_param_5];
	ld.param.u64 	%rd14, [make_reg_field1_blocking_param_6];
	ld.param.u64 	%rd15, [make_reg_field1_blocking_param_7];
	ld.param.f64 	%fd14, [make_reg_field1_blocking_param_8];
	mul.lo.s32 	%r12, %r11, %r9;
	cvt.s64.s32	%rd1, %r12;
	mov.u32 	%r13, %ctaid.x;
	mov.u32 	%r14, %ntid.x;
	mov.b32	%r15, %envreg3;
	mad.lo.s32 	%r16, %r13, %r14, %r15;
	mov.u32 	%r17, %tid.x;
	add.s32 	%r18, %r16, %r17;
	cvt.s64.s32	%rd2, %r18;
	or.b32  	%r19, %r18, %r12;
	cvt.s64.s32	%rd16, %r19;
	and.b64  	%rd17, %rd16, -4294967296;
	setp.eq.s64	%p1, %rd17, 0;
	@%p1 bra 	BB1_2;

	div.u64 	%rd38, %rd2, %rd1;
	rem.u64 	%rd39, %rd2, %rd1;
	bra.uni 	BB1_3;

BB1_2:
	cvt.u32.u64	%r20, %rd1;
	cvt.u32.u64	%r21, %rd2;
	div.u32 	%r22, %r21, %r20;
	rem.u32 	%r23, %r21, %r20;
	cvt.u64.u32	%rd38, %r22;
	cvt.u64.u32	%rd39, %r23;

BB1_3:
	cvt.s64.s32	%rd9, %r9;
	or.b64  	%rd18, %rd39, %rd9;
	and.b64  	%rd19, %rd18, -4294967296;
	setp.eq.s64	%p2, %rd19, 0;
	@%p2 bra 	BB1_5;

	div.u64 	%rd40, %rd39, %rd9;
	bra.uni 	BB1_6;

BB1_5:
	cvt.u32.u64	%r24, %rd9;
	cvt.u32.u64	%r25, %rd39;
	div.u32 	%r26, %r25, %r24;
	cvt.u64.u32	%rd40, %r26;

BB1_6:
	mov.f64 	%fd45, 0d0000000000000000;
	setp.lt.s32	%p3, %r8, 1;
	@%p3 bra 	BB1_13;

	cvt.u32.u64	%r28, %rd38;
	cvt.u32.u64	%r29, %rd40;
	mul.lo.s32 	%r30, %r29, %r9;
	cvt.u32.u64	%r31, %rd2;
	sub.s32 	%r32, %r31, %r30;
	cvt.u64.u32	%rd20, %r32;
	mul.lo.s64 	%rd21, %rd38, %rd1;
	sub.s64 	%rd22, %rd20, %rd21;
	cvt.u32.u64	%r33, %rd22;
	cvt.rn.f64.s32	%fd1, %r28;
	cvt.rn.f64.s32	%fd2, %r29;
	cvt.rn.f64.s32	%fd3, %r33;
	cvt.rn.f64.s32	%fd4, %r10;
	mov.f64 	%fd45, 0d0000000000000000;
	mov.u32 	%r47, 0;

BB1_8:
	mov.u32 	%r46, %r47;
	add.s32 	%r35, %r46, %r17;
	mul.wide.s32 	%rd23, %r35, 32;
	add.s64 	%rd24, %rd13, %rd23;
	ld.global.v2.f64 	{%fd17, %fd18}, [%rd24];
	ld.global.v2.f64 	{%fd21, %fd22}, [%rd24+16];
	mul.wide.s32 	%rd25, %r17, 32;
	mov.u64 	%rd26, make_reg_field1_blocking$loc_vecs;
	add.s64 	%rd27, %rd26, %rd25;
	st.shared.v2.f64 	[%rd27+16], {%fd21, %fd22};
	st.shared.v2.f64 	[%rd27], {%fd17, %fd18};
	bar.sync 	0;
	add.s32 	%r47, %r46, 64;
	min.s32 	%r2, %r8, %r47;
	mov.u32 	%r44, 0;
	setp.ge.s32	%p4, %r46, %r2;
	@%p4 bra 	BB1_12;

BB1_9:
	mul.wide.s32 	%rd28, %r44, 32;
	add.s64 	%rd30, %rd26, %rd28;
	ld.shared.v2.f64 	{%fd25, %fd26}, [%rd30+16];
	ld.shared.v2.f64 	{%fd27, %fd28}, [%rd30];
	mul.f64 	%fd31, %fd2, %fd28;
	fma.rn.f64 	%fd32, %fd1, %fd27, %fd31;
	fma.rn.f64 	%fd34, %fd3, %fd25, %fd32;
	fma.rn.f64 	%fd36, %fd26, 0d0000000000000000, %fd34;
	mul.f64 	%fd37, %fd36, %fd14;
	neg.f64 	%fd44, %fd37;
	abs.f64 	%fd8, %fd44;
	setp.ge.f64	%p5, %fd8, 0d4330000000000000;
	@%p5 bra 	BB1_11;

	add.f64 	%fd38, %fd8, 0d3FE0000000000000;
	cvt.rzi.f64.f64	%fd39, %fd38;
	setp.lt.f64	%p6, %fd8, 0d3FE0000000000000;
	selp.f64	%fd40, 0d0000000000000000, %fd39, %p6;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r38, %temp}, %fd40;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r39}, %fd40;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r40}, %fd44;
	}
	and.b32  	%r41, %r40, -2147483648;
	or.b32  	%r42, %r39, %r41;
	mov.b64 	%fd44, {%r38, %r42};

BB1_11:
	fma.rn.f64 	%fd41, %fd4, 0d3FE0000000000000, %fd44;
	add.f64 	%fd42, %fd41, 0d3FF0000000000000;
	cvt.rzi.u64.f64	%rd31, %fd42;
	mul.lo.s32 	%r43, %r46, %r10;
	cvt.s64.s32	%rd32, %r43;
	add.s64 	%rd33, %rd31, %rd32;
	shl.b64 	%rd34, %rd33, 3;
	add.s64 	%rd35, %rd14, %rd34;
	ld.global.f64 	%fd43, [%rd35];
	add.f64 	%fd45, %fd45, %fd43;
	add.s32 	%r44, %r44, 1;
	add.s32 	%r46, %r46, 1;
	setp.lt.s32	%p7, %r46, %r2;
	@%p7 bra 	BB1_9;

BB1_12:
	bar.sync 	0;
	setp.lt.s32	%p8, %r47, %r8;
	@%p8 bra 	BB1_8;

BB1_13:
	shl.b64 	%rd36, %rd2, 3;
	add.s64 	%rd37, %rd15, %rd36;
	st.global.f64 	[%rd37], %fd45;
	ret;
}

	// .globl	make_reg_field1_unroll
.entry make_reg_field1_unroll(
	.param .u32 make_reg_field1_unroll_param_0,
	.param .u32 make_reg_field1_unroll_param_1,
	.param .u32 make_reg_field1_unroll_param_2,
	.param .u32 make_reg_field1_unroll_param_3,
	.param .u32 make_reg_field1_unroll_param_4,
	.param .u64 .ptr .global .align 32 make_reg_field1_unroll_param_5,
	.param .u64 .ptr .global .align 8 make_reg_field1_unroll_param_6,
	.param .u64 .ptr .global .align 8 make_reg_field1_unroll_param_7,
	.param .f64 make_reg_field1_unroll_param_8
)
{
	.reg .pred 	%p<13>;
	.reg .b32 	%r<57>;
	.reg .f64 	%fd<111>;
	.reg .b64 	%rd<54>;


	ld.param.u32 	%r3, [make_reg_field1_unroll_param_0];
	ld.param.u32 	%r4, [make_reg_field1_unroll_param_2];
	ld.param.u32 	%r6, [make_reg_field1_unroll_param_3];
	ld.param.u32 	%r5, [make_reg_field1_unroll_param_4];
	ld.param.u64 	%rd14, [make_reg_field1_unroll_param_5];
	ld.param.u64 	%rd15, [make_reg_field1_unroll_param_6];
	ld.param.u64 	%rd16, [make_reg_field1_unroll_param_7];
	ld.param.f64 	%fd27, [make_reg_field1_unroll_param_8];
	mul.lo.s32 	%r7, %r6, %r4;
	cvt.s64.s32	%rd1, %r7;
	mov.u32 	%r8, %ctaid.x;
	mov.u32 	%r9, %ntid.x;
	mov.b32	%r10, %envreg3;
	mad.lo.s32 	%r11, %r8, %r9, %r10;
	mov.u32 	%r12, %tid.x;
	add.s32 	%r13, %r11, %r12;
	cvt.s64.s32	%rd2, %r13;
	or.b32  	%r14, %r13, %r7;
	cvt.s64.s32	%rd17, %r14;
	and.b64  	%rd18, %rd17, -4294967296;
	setp.eq.s64	%p1, %rd18, 0;
	@%p1 bra 	BB2_2;

	div.u64 	%rd51, %rd2, %rd1;
	rem.u64 	%rd52, %rd2, %rd1;
	bra.uni 	BB2_3;

BB2_2:
	cvt.u32.u64	%r15, %rd1;
	cvt.u32.u64	%r16, %rd2;
	div.u32 	%r17, %r16, %r15;
	rem.u32 	%r18, %r16, %r15;
	cvt.u64.u32	%rd51, %r17;
	cvt.u64.u32	%rd52, %r18;

BB2_3:
	cvt.s64.s32	%rd9, %r4;
	or.b64  	%rd19, %rd52, %rd9;
	and.b64  	%rd20, %rd19, -4294967296;
	setp.eq.s64	%p2, %rd20, 0;
	@%p2 bra 	BB2_5;

	div.u64 	%rd53, %rd52, %rd9;
	bra.uni 	BB2_6;

BB2_5:
	cvt.u32.u64	%r19, %rd9;
	cvt.u32.u64	%r20, %rd52;
	div.u32 	%r21, %r20, %r19;
	cvt.u64.u32	%rd53, %r21;

BB2_6:
	cvt.u32.u64	%r22, %rd51;
	cvt.u32.u64	%r23, %rd53;
	mul.lo.s32 	%r24, %r23, %r4;
	cvt.u32.u64	%r25, %rd2;
	sub.s32 	%r26, %r25, %r24;
	cvt.u64.u32	%rd21, %r26;
	mul.lo.s64 	%rd22, %rd51, %rd1;
	sub.s64 	%rd23, %rd21, %rd22;
	cvt.u32.u64	%r27, %rd23;
	cvt.rn.f64.s32	%fd1, %r22;
	cvt.rn.f64.s32	%fd2, %r23;
	cvt.rn.f64.s32	%fd3, %r27;
	mov.f64 	%fd110, 0d0000000000000000;
	setp.lt.s32	%p3, %r3, 1;
	@%p3 bra 	BB2_17;

	cvt.rn.f64.s32	%fd4, %r5;
	mov.f64 	%fd110, 0d0000000000000000;
	mov.u32 	%r56, 0;

BB2_8:
	mul.wide.s32 	%rd24, %r56, 32;
	add.s64 	%rd13, %rd14, %rd24;
	ld.global.v2.f64 	{%fd30, %fd31}, [%rd13+16];
	ld.global.v2.f64 	{%fd32, %fd33}, [%rd13];
	mul.f64 	%fd36, %fd2, %fd33;
	fma.rn.f64 	%fd37, %fd1, %fd32, %fd36;
	fma.rn.f64 	%fd39, %fd3, %fd30, %fd37;
	fma.rn.f64 	%fd41, %fd31, 0d0000000000000000, %fd39;
	mul.f64 	%fd42, %fd41, %fd27;
	neg.f64 	%fd106, %fd42;
	abs.f64 	%fd7, %fd106;
	setp.ge.f64	%p4, %fd7, 0d4330000000000000;
	@%p4 bra 	BB2_10;

	add.f64 	%fd43, %fd7, 0d3FE0000000000000;
	cvt.rzi.f64.f64	%fd44, %fd43;
	setp.lt.f64	%p5, %fd7, 0d3FE0000000000000;
	selp.f64	%fd45, 0d0000000000000000, %fd44, %p5;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r29, %temp}, %fd45;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r30}, %fd45;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r31}, %fd106;
	}
	and.b32  	%r32, %r31, -2147483648;
	or.b32  	%r33, %r30, %r32;
	mov.b64 	%fd106, {%r29, %r33};

BB2_10:
	fma.rn.f64 	%fd46, %fd4, 0d3FE0000000000000, %fd106;
	add.f64 	%fd47, %fd46, 0d3FF0000000000000;
	cvt.rzi.u64.f64	%rd25, %fd47;
	mul.lo.s32 	%r34, %r56, %r5;
	cvt.s64.s32	%rd26, %r34;
	add.s64 	%rd27, %rd25, %rd26;
	shl.b64 	%rd28, %rd27, 3;
	add.s64 	%rd29, %rd15, %rd28;
	ld.global.f64 	%fd48, [%rd29];
	add.f64 	%fd10, %fd110, %fd48;
	ld.global.v2.f64 	{%fd49, %fd50}, [%rd13+48];
	ld.global.v2.f64 	{%fd51, %fd52}, [%rd13+32];
	mul.f64 	%fd55, %fd2, %fd52;
	fma.rn.f64 	%fd56, %fd1, %fd51, %fd55;
	fma.rn.f64 	%fd58, %fd3, %fd49, %fd56;
	fma.rn.f64 	%fd60, %fd50, 0d0000000000000000, %fd58;
	mul.f64 	%fd61, %fd60, %fd27;
	neg.f64 	%fd107, %fd61;
	abs.f64 	%fd12, %fd107;
	setp.ge.f64	%p6, %fd12, 0d4330000000000000;
	@%p6 bra 	BB2_12;

	add.f64 	%fd62, %fd12, 0d3FE0000000000000;
	cvt.rzi.f64.f64	%fd63, %fd62;
	setp.lt.f64	%p7, %fd12, 0d3FE0000000000000;
	selp.f64	%fd64, 0d0000000000000000, %fd63, %p7;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r35, %temp}, %fd64;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r36}, %fd64;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r37}, %fd107;
	}
	and.b32  	%r38, %r37, -2147483648;
	or.b32  	%r39, %r36, %r38;
	mov.b64 	%fd107, {%r35, %r39};

BB2_12:
	add.s32 	%r40, %r56, 1;
	fma.rn.f64 	%fd65, %fd4, 0d3FE0000000000000, %fd107;
	add.f64 	%fd66, %fd65, 0d3FF0000000000000;
	cvt.rzi.u64.f64	%rd30, %fd66;
	mul.lo.s32 	%r41, %r40, %r5;
	cvt.s64.s32	%rd31, %r41;
	add.s64 	%rd32, %rd30, %rd31;
	shl.b64 	%rd33, %rd32, 3;
	add.s64 	%rd34, %rd15, %rd33;
	ld.global.f64 	%fd67, [%rd34];
	add.f64 	%fd15, %fd10, %fd67;
	ld.global.v2.f64 	{%fd68, %fd69}, [%rd13+80];
	ld.global.v2.f64 	{%fd70, %fd71}, [%rd13+64];
	mul.f64 	%fd74, %fd2, %fd71;
	fma.rn.f64 	%fd75, %fd1, %fd70, %fd74;
	fma.rn.f64 	%fd77, %fd3, %fd68, %fd75;
	fma.rn.f64 	%fd79, %fd69, 0d0000000000000000, %fd77;
	mul.f64 	%fd80, %fd79, %fd27;
	neg.f64 	%fd108, %fd80;
	abs.f64 	%fd17, %fd108;
	setp.ge.f64	%p8, %fd17, 0d4330000000000000;
	@%p8 bra 	BB2_14;

	add.f64 	%fd81, %fd17, 0d3FE0000000000000;
	cvt.rzi.f64.f64	%fd82, %fd81;
	setp.lt.f64	%p9, %fd17, 0d3FE0000000000000;
	selp.f64	%fd83, 0d0000000000000000, %fd82, %p9;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r42, %temp}, %fd83;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r43}, %fd83;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r44}, %fd108;
	}
	and.b32  	%r45, %r44, -2147483648;
	or.b32  	%r46, %r43, %r45;
	mov.b64 	%fd108, {%r42, %r46};

BB2_14:
	add.s32 	%r47, %r56, 2;
	fma.rn.f64 	%fd84, %fd4, 0d3FE0000000000000, %fd108;
	add.f64 	%fd85, %fd84, 0d3FF0000000000000;
	cvt.rzi.u64.f64	%rd37, %fd85;
	mul.lo.s32 	%r48, %r47, %r5;
	cvt.s64.s32	%rd38, %r48;
	add.s64 	%rd39, %rd37, %rd38;
	shl.b64 	%rd40, %rd39, 3;
	add.s64 	%rd41, %rd15, %rd40;
	ld.global.f64 	%fd86, [%rd41];
	add.f64 	%fd20, %fd15, %fd86;
	ld.global.v2.f64 	{%fd87, %fd88}, [%rd13+112];
	ld.global.v2.f64 	{%fd89, %fd90}, [%rd13+96];
	mul.f64 	%fd93, %fd2, %fd90;
	fma.rn.f64 	%fd94, %fd1, %fd89, %fd93;
	fma.rn.f64 	%fd96, %fd3, %fd87, %fd94;
	fma.rn.f64 	%fd98, %fd88, 0d0000000000000000, %fd96;
	mul.f64 	%fd99, %fd98, %fd27;
	neg.f64 	%fd109, %fd99;
	abs.f64 	%fd22, %fd109;
	setp.ge.f64	%p10, %fd22, 0d4330000000000000;
	@%p10 bra 	BB2_16;

	add.f64 	%fd100, %fd22, 0d3FE0000000000000;
	cvt.rzi.f64.f64	%fd101, %fd100;
	setp.lt.f64	%p11, %fd22, 0d3FE0000000000000;
	selp.f64	%fd102, 0d0000000000000000, %fd101, %p11;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r49, %temp}, %fd102;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r50}, %fd102;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r51}, %fd109;
	}
	and.b32  	%r52, %r51, -2147483648;
	or.b32  	%r53, %r50, %r52;
	mov.b64 	%fd109, {%r49, %r53};

BB2_16:
	add.s32 	%r54, %r56, 3;
	fma.rn.f64 	%fd103, %fd4, 0d3FE0000000000000, %fd109;
	add.f64 	%fd104, %fd103, 0d3FF0000000000000;
	cvt.rzi.u64.f64	%rd44, %fd104;
	mul.lo.s32 	%r55, %r54, %r5;
	cvt.s64.s32	%rd45, %r55;
	add.s64 	%rd46, %rd44, %rd45;
	shl.b64 	%rd47, %rd46, 3;
	add.s64 	%rd48, %rd15, %rd47;
	ld.global.f64 	%fd105, [%rd48];
	add.f64 	%fd110, %fd20, %fd105;
	add.s32 	%r56, %r56, 4;
	setp.lt.s32	%p12, %r56, %r3;
	@%p12 bra 	BB2_8;

BB2_17:
	shl.b64 	%rd49, %rd2, 3;
	add.s64 	%rd50, %rd16, %rd49;
	st.global.f64 	[%rd50], %fd110;
	ret;
}

	// .globl	make_reg_field1_blocking_unroll
.entry make_reg_field1_blocking_unroll(
	.param .u32 make_reg_field1_blocking_unroll_param_0,
	.param .u32 make_reg_field1_blocking_unroll_param_1,
	.param .u32 make_reg_field1_blocking_unroll_param_2,
	.param .u32 make_reg_field1_blocking_unroll_param_3,
	.param .u32 make_reg_field1_blocking_unroll_param_4,
	.param .u64 .ptr .global .align 32 make_reg_field1_blocking_unroll_param_5,
	.param .u64 .ptr .global .align 8 make_reg_field1_blocking_unroll_param_6,
	.param .u64 .ptr .global .align 8 make_reg_field1_blocking_unroll_param_7,
	.param .f64 make_reg_field1_blocking_unroll_param_8
)
{
	.reg .pred 	%p<15>;
	.reg .b32 	%r<69>;
	.reg .f64 	%fd<121>;
	.reg .b64 	%rd<57>;
	// demoted variable
	.shared .align 32 .b8 make_reg_field1_blocking_unroll$loc_vecs[2048];

	ld.param.u32 	%r8, [make_reg_field1_blocking_unroll_param_0];
	ld.param.u32 	%r9, [make_reg_field1_blocking_unroll_param_2];
	ld.param.u32 	%r11, [make_reg_field1_blocking_unroll_param_3];
	ld.param.u32 	%r10, [make_reg_field1_blocking_unroll_param_4];
	ld.param.u64 	%rd15, [make_reg_field1_blocking_unroll_param_5];
	ld.param.u64 	%rd16, [make_reg_field1_blocking_unroll_param_6];
	ld.param.u64 	%rd17, [make_reg_field1_blocking_unroll_param_7];
	ld.param.f64 	%fd29, [make_reg_field1_blocking_unroll_param_8];
	mul.lo.s32 	%r12, %r11, %r9;
	cvt.s64.s32	%rd1, %r12;
	mov.u32 	%r13, %ctaid.x;
	mov.u32 	%r14, %ntid.x;
	mov.b32	%r15, %envreg3;
	mad.lo.s32 	%r16, %r13, %r14, %r15;
	mov.u32 	%r17, %tid.x;
	add.s32 	%r18, %r16, %r17;
	cvt.s64.s32	%rd2, %r18;
	or.b32  	%r19, %r18, %r12;
	cvt.s64.s32	%rd18, %r19;
	and.b64  	%rd19, %rd18, -4294967296;
	setp.eq.s64	%p1, %rd19, 0;
	@%p1 bra 	BB3_2;

	div.u64 	%rd54, %rd2, %rd1;
	rem.u64 	%rd55, %rd2, %rd1;
	bra.uni 	BB3_3;

BB3_2:
	cvt.u32.u64	%r20, %rd1;
	cvt.u32.u64	%r21, %rd2;
	div.u32 	%r22, %r21, %r20;
	rem.u32 	%r23, %r21, %r20;
	cvt.u64.u32	%rd54, %r22;
	cvt.u64.u32	%rd55, %r23;

BB3_3:
	cvt.s64.s32	%rd9, %r9;
	or.b64  	%rd20, %rd55, %rd9;
	and.b64  	%rd21, %rd20, -4294967296;
	setp.eq.s64	%p2, %rd21, 0;
	@%p2 bra 	BB3_5;

	div.u64 	%rd56, %rd55, %rd9;
	bra.uni 	BB3_6;

BB3_5:
	cvt.u32.u64	%r24, %rd9;
	cvt.u32.u64	%r25, %rd55;
	div.u32 	%r26, %r25, %r24;
	cvt.u64.u32	%rd56, %r26;

BB3_6:
	cvt.u32.u64	%r27, %rd54;
	cvt.u32.u64	%r28, %rd56;
	mul.lo.s32 	%r29, %r28, %r9;
	cvt.u32.u64	%r30, %rd2;
	sub.s32 	%r31, %r30, %r29;
	cvt.u64.u32	%rd22, %r31;
	mul.lo.s64 	%rd23, %rd54, %rd1;
	sub.s64 	%rd24, %rd22, %rd23;
	cvt.u32.u64	%r32, %rd24;
	cvt.rn.f64.s32	%fd1, %r27;
	cvt.rn.f64.s32	%fd2, %r28;
	cvt.rn.f64.s32	%fd3, %r32;
	mov.f64 	%fd120, 0d0000000000000000;
	setp.lt.s32	%p3, %r8, 1;
	@%p3 bra 	BB3_19;

	cvt.rn.f64.s32	%fd4, %r10;
	mov.f64 	%fd120, 0d0000000000000000;
	mov.u32 	%r68, 0;

BB3_8:
	mov.u32 	%r67, %r68;
	add.s32 	%r35, %r67, %r17;
	mul.wide.s32 	%rd25, %r35, 32;
	add.s64 	%rd26, %rd15, %rd25;
	ld.global.v2.f64 	{%fd32, %fd33}, [%rd26];
	ld.global.v2.f64 	{%fd36, %fd37}, [%rd26+16];
	mul.wide.s32 	%rd27, %r17, 32;
	mov.u64 	%rd28, make_reg_field1_blocking_unroll$loc_vecs;
	add.s64 	%rd29, %rd28, %rd27;
	st.shared.v2.f64 	[%rd29+16], {%fd36, %fd37};
	st.shared.v2.f64 	[%rd29], {%fd32, %fd33};
	bar.sync 	0;
	add.s32 	%r68, %r67, 64;
	min.s32 	%r2, %r8, %r68;
	mov.u32 	%r65, 0;
	setp.ge.s32	%p4, %r67, %r2;
	@%p4 bra 	BB3_18;

BB3_9:
	mul.wide.s32 	%rd30, %r65, 32;
	add.s64 	%rd13, %rd28, %rd30;
	ld.shared.v2.f64 	{%fd40, %fd41}, [%rd13+16];
	ld.shared.v2.f64 	{%fd42, %fd43}, [%rd13];
	mul.f64 	%fd46, %fd2, %fd43;
	fma.rn.f64 	%fd47, %fd1, %fd42, %fd46;
	fma.rn.f64 	%fd49, %fd3, %fd40, %fd47;
	fma.rn.f64 	%fd51, %fd41, 0d0000000000000000, %fd49;
	mul.f64 	%fd52, %fd51, %fd29;
	neg.f64 	%fd116, %fd52;
	abs.f64 	%fd8, %fd116;
	setp.ge.f64	%p5, %fd8, 0d4330000000000000;
	@%p5 bra 	BB3_11;

	add.f64 	%fd53, %fd8, 0d3FE0000000000000;
	cvt.rzi.f64.f64	%fd54, %fd53;
	setp.lt.f64	%p6, %fd8, 0d3FE0000000000000;
	selp.f64	%fd55, 0d0000000000000000, %fd54, %p6;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r38, %temp}, %fd55;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r39}, %fd55;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r40}, %fd116;
	}
	and.b32  	%r41, %r40, -2147483648;
	or.b32  	%r42, %r39, %r41;
	mov.b64 	%fd116, {%r38, %r42};

BB3_11:
	fma.rn.f64 	%fd56, %fd4, 0d3FE0000000000000, %fd116;
	add.f64 	%fd57, %fd56, 0d3FF0000000000000;
	cvt.rzi.u64.f64	%rd32, %fd57;
	mul.lo.s32 	%r43, %r67, %r10;
	cvt.s64.s32	%rd33, %r43;
	add.s64 	%rd34, %rd32, %rd33;
	shl.b64 	%rd35, %rd34, 3;
	add.s64 	%rd36, %rd16, %rd35;
	ld.global.f64 	%fd58, [%rd36];
	add.f64 	%fd11, %fd120, %fd58;
	ld.shared.v2.f64 	{%fd59, %fd60}, [%rd13+48];
	ld.shared.v2.f64 	{%fd61, %fd62}, [%rd13+32];
	mul.f64 	%fd65, %fd2, %fd62;
	fma.rn.f64 	%fd66, %fd1, %fd61, %fd65;
	fma.rn.f64 	%fd68, %fd3, %fd59, %fd66;
	fma.rn.f64 	%fd70, %fd60, 0d0000000000000000, %fd68;
	mul.f64 	%fd71, %fd70, %fd29;
	neg.f64 	%fd117, %fd71;
	abs.f64 	%fd13, %fd117;
	setp.ge.f64	%p7, %fd13, 0d4330000000000000;
	@%p7 bra 	BB3_13;

	add.f64 	%fd72, %fd13, 0d3FE0000000000000;
	cvt.rzi.f64.f64	%fd73, %fd72;
	setp.lt.f64	%p8, %fd13, 0d3FE0000000000000;
	selp.f64	%fd74, 0d0000000000000000, %fd73, %p8;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r44, %temp}, %fd74;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r45}, %fd74;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r46}, %fd117;
	}
	and.b32  	%r47, %r46, -2147483648;
	or.b32  	%r48, %r45, %r47;
	mov.b64 	%fd117, {%r44, %r48};

BB3_13:
	fma.rn.f64 	%fd75, %fd4, 0d3FE0000000000000, %fd117;
	add.f64 	%fd76, %fd75, 0d3FF0000000000000;
	cvt.rzi.u64.f64	%rd37, %fd76;
	add.s32 	%r49, %r67, 1;
	mul.lo.s32 	%r50, %r49, %r10;
	cvt.s64.s32	%rd38, %r50;
	add.s64 	%rd39, %rd37, %rd38;
	shl.b64 	%rd40, %rd39, 3;
	add.s64 	%rd41, %rd16, %rd40;
	ld.global.f64 	%fd77, [%rd41];
	add.f64 	%fd16, %fd11, %fd77;
	ld.shared.v2.f64 	{%fd78, %fd79}, [%rd13+80];
	ld.shared.v2.f64 	{%fd80, %fd81}, [%rd13+64];
	mul.f64 	%fd84, %fd2, %fd81;
	fma.rn.f64 	%fd85, %fd1, %fd80, %fd84;
	fma.rn.f64 	%fd87, %fd3, %fd78, %fd85;
	fma.rn.f64 	%fd89, %fd79, 0d0000000000000000, %fd87;
	mul.f64 	%fd90, %fd89, %fd29;
	neg.f64 	%fd118, %fd90;
	abs.f64 	%fd18, %fd118;
	setp.ge.f64	%p9, %fd18, 0d4330000000000000;
	@%p9 bra 	BB3_15;

	add.f64 	%fd91, %fd18, 0d3FE0000000000000;
	cvt.rzi.f64.f64	%fd92, %fd91;
	setp.lt.f64	%p10, %fd18, 0d3FE0000000000000;
	selp.f64	%fd93, 0d0000000000000000, %fd92, %p10;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r51, %temp}, %fd93;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r52}, %fd93;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r53}, %fd118;
	}
	and.b32  	%r54, %r53, -2147483648;
	or.b32  	%r55, %r52, %r54;
	mov.b64 	%fd118, {%r51, %r55};

BB3_15:
	fma.rn.f64 	%fd94, %fd4, 0d3FE0000000000000, %fd118;
	add.f64 	%fd95, %fd94, 0d3FF0000000000000;
	cvt.rzi.u64.f64	%rd42, %fd95;
	add.s32 	%r56, %r67, 2;
	mul.lo.s32 	%r57, %r56, %r10;
	cvt.s64.s32	%rd43, %r57;
	add.s64 	%rd44, %rd42, %rd43;
	shl.b64 	%rd45, %rd44, 3;
	add.s64 	%rd46, %rd16, %rd45;
	ld.global.f64 	%fd96, [%rd46];
	add.f64 	%fd21, %fd16, %fd96;
	ld.shared.v2.f64 	{%fd97, %fd98}, [%rd13+112];
	ld.shared.v2.f64 	{%fd99, %fd100}, [%rd13+96];
	mul.f64 	%fd103, %fd2, %fd100;
	fma.rn.f64 	%fd104, %fd1, %fd99, %fd103;
	fma.rn.f64 	%fd106, %fd3, %fd97, %fd104;
	fma.rn.f64 	%fd108, %fd98, 0d0000000000000000, %fd106;
	mul.f64 	%fd109, %fd108, %fd29;
	neg.f64 	%fd119, %fd109;
	abs.f64 	%fd23, %fd119;
	setp.ge.f64	%p11, %fd23, 0d4330000000000000;
	@%p11 bra 	BB3_17;

	add.f64 	%fd110, %fd23, 0d3FE0000000000000;
	cvt.rzi.f64.f64	%fd111, %fd110;
	setp.lt.f64	%p12, %fd23, 0d3FE0000000000000;
	selp.f64	%fd112, 0d0000000000000000, %fd111, %p12;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r58, %temp}, %fd112;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r59}, %fd112;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r60}, %fd119;
	}
	and.b32  	%r61, %r60, -2147483648;
	or.b32  	%r62, %r59, %r61;
	mov.b64 	%fd119, {%r58, %r62};

BB3_17:
	fma.rn.f64 	%fd113, %fd4, 0d3FE0000000000000, %fd119;
	add.f64 	%fd114, %fd113, 0d3FF0000000000000;
	cvt.rzi.u64.f64	%rd47, %fd114;
	add.s32 	%r63, %r67, 3;
	mul.lo.s32 	%r64, %r63, %r10;
	cvt.s64.s32	%rd48, %r64;
	add.s64 	%rd49, %rd47, %rd48;
	shl.b64 	%rd50, %rd49, 3;
	add.s64 	%rd51, %rd16, %rd50;
	ld.global.f64 	%fd115, [%rd51];
	add.f64 	%fd120, %fd21, %fd115;
	bar.sync 	0;
	add.s32 	%r65, %r65, 4;
	add.s32 	%r67, %r67, 4;
	setp.lt.s32	%p13, %r67, %r2;
	@%p13 bra 	BB3_9;

BB3_18:
	setp.lt.s32	%p14, %r68, %r8;
	@%p14 bra 	BB3_8;

BB3_19:
	shl.b64 	%rd52, %rd2, 3;
	add.s64 	%rd53, %rd17, %rd52;
	st.global.f64 	[%rd53], %fd120;
	ret;
}

	// .globl	make_reg_field_outofcore_blocking
.entry make_reg_field_outofcore_blocking(
	.param .u32 make_reg_field_outofcore_blocking_param_0,
	.param .u32 make_reg_field_outofcore_blocking_param_1,
	.param .u32 make_reg_field_outofcore_blocking_param_2,
	.param .u32 make_reg_field_outofcore_blocking_param_3,
	.param .u32 make_reg_field_outofcore_blocking_param_4,
	.param .u64 .ptr .global .align 32 make_reg_field_outofcore_blocking_param_5,
	.param .u64 .ptr .global .align 8 make_reg_field_outofcore_blocking_param_6,
	.param .u64 .ptr .global .align 8 make_reg_field_outofcore_blocking_param_7,
	.param .f64 make_reg_field_outofcore_blocking_param_8,
	.param .u64 make_reg_field_outofcore_blocking_param_9
)
{
	.reg .pred 	%p<9>;
	.reg .b32 	%r<45>;
	.reg .f64 	%fd<46>;
	.reg .b64 	%rd<45>;
	// demoted variable
	.shared .align 32 .b8 make_reg_field_outofcore_blocking$loc_vecs[2048];

	ld.param.u32 	%r10, [make_reg_field_outofcore_blocking_param_0];
	ld.param.u32 	%r11, [make_reg_field_outofcore_blocking_param_2];
	ld.param.u32 	%r13, [make_reg_field_outofcore_blocking_param_3];
	ld.param.u32 	%r12, [make_reg_field_outofcore_blocking_param_4];
	ld.param.u64 	%rd15, [make_reg_field_outofcore_blocking_param_5];
	ld.param.u64 	%rd16, [make_reg_field_outofcore_blocking_param_6];
	ld.param.u64 	%rd17, [make_reg_field_outofcore_blocking_param_7];
	ld.param.f64 	%fd14, [make_reg_field_outofcore_blocking_param_8];
	ld.param.u64 	%rd18, [make_reg_field_outofcore_blocking_param_9];
	mul.lo.s32 	%r14, %r13, %r11;
	cvt.s64.s32	%rd1, %r14;
	mov.u32 	%r15, %ctaid.x;
	mov.u32 	%r16, %ntid.x;
	mov.b32	%r17, %envreg3;
	mad.lo.s32 	%r18, %r15, %r16, %r17;
	mov.u32 	%r19, %tid.x;
	add.s32 	%r20, %r18, %r19;
	cvt.s64.s32	%rd2, %r20;
	add.s64 	%rd3, %rd2, %rd18;
	or.b64  	%rd19, %rd3, %rd1;
	and.b64  	%rd20, %rd19, -4294967296;
	setp.eq.s64	%p1, %rd20, 0;
	@%p1 bra 	BB4_2;

	div.u64 	%rd42, %rd3, %rd1;
	rem.u64 	%rd43, %rd3, %rd1;
	bra.uni 	BB4_3;

BB4_2:
	cvt.u32.u64	%r21, %rd1;
	cvt.u32.u64	%r22, %rd3;
	div.u32 	%r23, %r22, %r21;
	rem.u32 	%r24, %r22, %r21;
	cvt.u64.u32	%rd42, %r23;
	cvt.u64.u32	%rd43, %r24;

BB4_3:
	cvt.s64.s32	%rd10, %r11;
	or.b64  	%rd21, %rd43, %rd10;
	and.b64  	%rd22, %rd21, -4294967296;
	setp.eq.s64	%p2, %rd22, 0;
	@%p2 bra 	BB4_5;

	div.u64 	%rd44, %rd43, %rd10;
	bra.uni 	BB4_6;

BB4_5:
	cvt.u32.u64	%r25, %rd10;
	cvt.u32.u64	%r26, %rd43;
	div.u32 	%r27, %r26, %r25;
	cvt.u64.u32	%rd44, %r27;

BB4_6:
	cvt.u32.u64	%r1, %rd42;
	cvt.u32.u64	%r2, %rd44;
	mul.lo.s32 	%r28, %r2, %r11;
	cvt.u64.u32	%rd23, %r28;
	cvt.s64.s32 	%rd24, %rd42;
	mul.lo.s64 	%rd25, %rd24, %rd1;
	sub.s64 	%rd26, %rd3, %rd25;
	sub.s64 	%rd14, %rd26, %rd23;
	mov.f64 	%fd45, 0d0000000000000000;
	setp.lt.s32	%p3, %r10, 1;
	@%p3 bra 	BB4_13;

	cvt.u32.u64	%r30, %rd14;
	cvt.rn.f64.s32	%fd1, %r1;
	cvt.rn.f64.s32	%fd2, %r2;
	cvt.rn.f64.s32	%fd3, %r30;
	cvt.rn.f64.s32	%fd4, %r12;
	mov.f64 	%fd45, 0d0000000000000000;
	mov.u32 	%r44, 0;

BB4_8:
	mov.u32 	%r43, %r44;
	add.s32 	%r32, %r43, %r19;
	mul.wide.s32 	%rd27, %r32, 32;
	add.s64 	%rd28, %rd15, %rd27;
	ld.global.v2.f64 	{%fd17, %fd18}, [%rd28];
	ld.global.v2.f64 	{%fd21, %fd22}, [%rd28+16];
	mul.wide.s32 	%rd29, %r19, 32;
	mov.u64 	%rd30, make_reg_field_outofcore_blocking$loc_vecs;
	add.s64 	%rd31, %rd30, %rd29;
	st.shared.v2.f64 	[%rd31+16], {%fd21, %fd22};
	st.shared.v2.f64 	[%rd31], {%fd17, %fd18};
	bar.sync 	0;
	add.s32 	%r44, %r43, 64;
	min.s32 	%r4, %r10, %r44;
	mov.u32 	%r41, 0;
	setp.ge.s32	%p4, %r43, %r4;
	@%p4 bra 	BB4_12;

BB4_9:
	mul.wide.s32 	%rd32, %r41, 32;
	add.s64 	%rd34, %rd30, %rd32;
	ld.shared.v2.f64 	{%fd25, %fd26}, [%rd34+16];
	ld.shared.v2.f64 	{%fd27, %fd28}, [%rd34];
	mul.f64 	%fd31, %fd2, %fd28;
	fma.rn.f64 	%fd32, %fd1, %fd27, %fd31;
	fma.rn.f64 	%fd34, %fd3, %fd25, %fd32;
	fma.rn.f64 	%fd36, %fd26, 0d0000000000000000, %fd34;
	mul.f64 	%fd37, %fd36, %fd14;
	neg.f64 	%fd44, %fd37;
	abs.f64 	%fd8, %fd44;
	setp.ge.f64	%p5, %fd8, 0d4330000000000000;
	@%p5 bra 	BB4_11;

	add.f64 	%fd38, %fd8, 0d3FE0000000000000;
	cvt.rzi.f64.f64	%fd39, %fd38;
	setp.lt.f64	%p6, %fd8, 0d3FE0000000000000;
	selp.f64	%fd40, 0d0000000000000000, %fd39, %p6;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r35, %temp}, %fd40;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r36}, %fd40;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r37}, %fd44;
	}
	and.b32  	%r38, %r37, -2147483648;
	or.b32  	%r39, %r36, %r38;
	mov.b64 	%fd44, {%r35, %r39};

BB4_11:
	fma.rn.f64 	%fd41, %fd4, 0d3FE0000000000000, %fd44;
	add.f64 	%fd42, %fd41, 0d3FF0000000000000;
	cvt.rzi.u64.f64	%rd35, %fd42;
	mul.lo.s32 	%r40, %r43, %r12;
	cvt.s64.s32	%rd36, %r40;
	add.s64 	%rd37, %rd35, %rd36;
	shl.b64 	%rd38, %rd37, 3;
	add.s64 	%rd39, %rd16, %rd38;
	ld.global.f64 	%fd43, [%rd39];
	add.f64 	%fd45, %fd45, %fd43;
	add.s32 	%r41, %r41, 1;
	add.s32 	%r43, %r43, 1;
	setp.lt.s32	%p7, %r43, %r4;
	@%p7 bra 	BB4_9;

BB4_12:
	bar.sync 	0;
	setp.lt.s32	%p8, %r44, %r10;
	@%p8 bra 	BB4_8;

BB4_13:
	shl.b64 	%rd40, %rd2, 3;
	add.s64 	%rd41, %rd17, %rd40;
	st.global.f64 	[%rd41], %fd45;
	ret;
}

	// .globl	make_reg_field2
.entry make_reg_field2(
	.param .u32 make_reg_field2_param_0,
	.param .u32 make_reg_field2_param_1,
	.param .u32 make_reg_field2_param_2,
	.param .u32 make_reg_field2_param_3,
	.param .u32 make_reg_field2_param_4,
	.param .u64 .ptr .global .align 32 make_reg_field2_param_5,
	.param .u64 .ptr .global .align 8 make_reg_field2_param_6,
	.param .u64 .ptr .global .align 8 make_reg_field2_param_7,
	.param .f64 make_reg_field2_param_8
)
{
	.reg .pred 	%p<9>;
	.reg .b32 	%r<32>;
	.reg .f64 	%fd<32>;
	.reg .b64 	%rd<16>;


	ld.param.u32 	%r7, [make_reg_field2_param_1];
	ld.param.u32 	%r8, [make_reg_field2_param_2];
	ld.param.u32 	%r9, [make_reg_field2_param_3];
	ld.param.u32 	%r10, [make_reg_field2_param_4];
	ld.param.u64 	%rd6, [make_reg_field2_param_5];
	ld.param.u64 	%rd7, [make_reg_field2_param_6];
	ld.param.u64 	%rd8, [make_reg_field2_param_7];
	ld.param.f64 	%fd8, [make_reg_field2_param_8];
	setp.lt.s32	%p1, %r7, 1;
	@%p1 bra 	BB5_11;

	mov.b32	%r12, %envreg3;
	mov.u32 	%r13, %ctaid.x;
	mov.u32 	%r14, %ntid.x;
	mad.lo.s32 	%r15, %r13, %r14, %r12;
	mov.u32 	%r16, %tid.x;
	add.s32 	%r17, %r15, %r16;
	mul.wide.s32 	%rd9, %r17, 32;
	add.s64 	%rd1, %rd6, %rd9;
	cvt.rn.f64.s32	%fd1, %r10;
	mul.lo.s32 	%r18, %r17, %r10;
	cvt.s64.s32	%rd2, %r18;
	mov.u32 	%r29, 0;

BB5_2:
	setp.lt.s32	%p2, %r8, 1;
	@%p2 bra 	BB5_10;

	cvt.rn.f64.s32	%fd2, %r29;
	mov.u32 	%r30, 0;

BB5_4:
	setp.lt.s32	%p3, %r9, 1;
	@%p3 bra 	BB5_9;

	mul.lo.s32 	%r21, %r9, %r8;
	mul.lo.s32 	%r22, %r9, %r30;
	mad.lo.s32 	%r23, %r21, %r29, %r22;
	mul.wide.s32 	%rd10, %r23, 8;
	add.s64 	%rd15, %rd8, %rd10;
	cvt.rn.f64.s32	%fd3, %r30;
	mov.u32 	%r31, 0;

BB5_6:
	ld.global.v2.f64 	{%fd9, %fd10}, [%rd1+16];
	ld.global.v2.f64 	{%fd11, %fd12}, [%rd1];
	mul.f64 	%fd14, %fd2, %fd11;
	neg.f64 	%fd15, %fd14;
	mul.f64 	%fd17, %fd3, %fd12;
	sub.f64 	%fd18, %fd15, %fd17;
	cvt.rn.f64.s32	%fd20, %r31;
	mul.f64 	%fd21, %fd20, %fd9;
	sub.f64 	%fd22, %fd18, %fd21;
	mul.f64 	%fd31, %fd22, %fd8;
	abs.f64 	%fd5, %fd31;
	setp.ge.f64	%p4, %fd5, 0d4330000000000000;
	@%p4 bra 	BB5_8;

	add.f64 	%fd23, %fd5, 0d3FE0000000000000;
	cvt.rzi.f64.f64	%fd24, %fd23;
	setp.lt.f64	%p5, %fd5, 0d3FE0000000000000;
	selp.f64	%fd25, 0d0000000000000000, %fd24, %p5;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r24, %temp}, %fd25;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r25}, %fd25;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r26}, %fd31;
	}
	and.b32  	%r27, %r26, -2147483648;
	or.b32  	%r28, %r25, %r27;
	mov.b64 	%fd31, {%r24, %r28};

BB5_8:
	fma.rn.f64 	%fd26, %fd1, 0d3FE0000000000000, %fd31;
	add.f64 	%fd27, %fd26, 0d3FF0000000000000;
	cvt.rzi.s64.f64	%rd11, %fd27;
	add.s64 	%rd12, %rd11, %rd2;
	shl.b64 	%rd13, %rd12, 3;
	add.s64 	%rd14, %rd7, %rd13;
	ld.volatile.global.f64 	%fd28, [%rd15];
	ld.global.f64 	%fd29, [%rd14];
	add.f64 	%fd30, %fd29, %fd28;
	st.volatile.global.f64 	[%rd15], %fd30;
	add.s64 	%rd15, %rd15, 8;
	add.s32 	%r31, %r31, 1;
	setp.lt.s32	%p6, %r31, %r9;
	@%p6 bra 	BB5_6;

BB5_9:
	add.s32 	%r30, %r30, 1;
	setp.lt.s32	%p7, %r30, %r8;
	@%p7 bra 	BB5_4;

BB5_10:
	add.s32 	%r29, %r29, 1;
	setp.lt.s32	%p8, %r29, %r7;
	@%p8 bra 	BB5_2;

BB5_11:
	ret;
}

	// .globl	make_reg_field3
.entry make_reg_field3(
	.param .u32 make_reg_field3_param_0,
	.param .u32 make_reg_field3_param_1,
	.param .u32 make_reg_field3_param_2,
	.param .u32 make_reg_field3_param_3,
	.param .u32 make_reg_field3_param_4,
	.param .u64 .ptr .global .align 32 make_reg_field3_param_5,
	.param .u64 .ptr .global .align 8 make_reg_field3_param_6,
	.param .u64 .ptr .global .align 8 make_reg_field3_param_7,
	.param .f64 make_reg_field3_param_8
)
{
	.reg .pred 	%p<5>;
	.reg .b32 	%r<34>;
	.reg .f64 	%fd<32>;
	.reg .b64 	%rd<36>;


	ld.param.u32 	%r4, [make_reg_field3_param_0];
	ld.param.u32 	%r2, [make_reg_field3_param_2];
	ld.param.u32 	%r5, [make_reg_field3_param_3];
	ld.param.u32 	%r3, [make_reg_field3_param_4];
	ld.param.u64 	%rd13, [make_reg_field3_param_5];
	ld.param.u64 	%rd14, [make_reg_field3_param_6];
	ld.param.u64 	%rd15, [make_reg_field3_param_7];
	ld.param.f64 	%fd5, [make_reg_field3_param_8];
	mul.lo.s32 	%r6, %r5, %r2;
	cvt.s64.s32	%rd1, %r6;
	mov.u32 	%r7, %ctaid.x;
	mov.u32 	%r8, %ntid.x;
	mov.b32	%r9, %envreg3;
	mad.lo.s32 	%r10, %r7, %r8, %r9;
	mov.u32 	%r11, %tid.x;
	add.s32 	%r12, %r10, %r11;
	div.s32 	%r13, %r12, %r4;
	rem.s32 	%r1, %r12, %r4;
	cvt.s64.s32	%rd2, %r13;
	or.b32  	%r14, %r13, %r6;
	cvt.s64.s32	%rd16, %r14;
	and.b64  	%rd17, %rd16, -4294967296;
	setp.eq.s64	%p1, %rd17, 0;
	@%p1 bra 	BB6_2;

	div.u64 	%rd33, %rd2, %rd1;
	rem.u64 	%rd34, %rd2, %rd1;
	bra.uni 	BB6_3;

BB6_2:
	cvt.u32.u64	%r15, %rd1;
	cvt.u32.u64	%r16, %rd2;
	div.u32 	%r17, %r16, %r15;
	rem.u32 	%r18, %r16, %r15;
	cvt.u64.u32	%rd33, %r17;
	cvt.u64.u32	%rd34, %r18;

BB6_3:
	cvt.s64.s32	%rd9, %r2;
	or.b64  	%rd18, %rd34, %rd9;
	and.b64  	%rd19, %rd18, -4294967296;
	setp.eq.s64	%p2, %rd19, 0;
	@%p2 bra 	BB6_5;

	div.u64 	%rd35, %rd34, %rd9;
	bra.uni 	BB6_6;

BB6_5:
	cvt.u32.u64	%r19, %rd9;
	cvt.u32.u64	%r20, %rd34;
	div.u32 	%r21, %r20, %r19;
	cvt.u64.u32	%rd35, %r21;

BB6_6:
	cvt.u32.u64	%r22, %rd33;
	cvt.u32.u64	%r23, %rd35;
	mul.lo.s32 	%r24, %r23, %r2;
	cvt.u32.u64	%r25, %rd2;
	sub.s32 	%r26, %r25, %r24;
	cvt.u64.u32	%rd20, %r26;
	mul.lo.s64 	%rd21, %rd33, %rd1;
	sub.s64 	%rd22, %rd20, %rd21;
	cvt.u32.u64	%r27, %rd22;
	cvt.rn.f64.s32	%fd6, %r27;
	cvt.rn.f64.s32	%fd7, %r23;
	mul.wide.s32 	%rd23, %r1, 32;
	add.s64 	%rd24, %rd13, %rd23;
	ld.global.v2.f64 	{%fd8, %fd9}, [%rd24+16];
	ld.global.v2.f64 	{%fd10, %fd11}, [%rd24];
	mul.f64 	%fd14, %fd11, %fd7;
	fma.rn.f64 	%fd15, %fd6, %fd10, %fd14;
	cvt.rn.f64.s32	%fd17, %r22;
	fma.rn.f64 	%fd18, %fd17, %fd8, %fd15;
	fma.rn.f64 	%fd20, %fd9, 0d0000000000000000, %fd18;
	mul.f64 	%fd21, %fd20, %fd5;
	neg.f64 	%fd31, %fd21;
	abs.f64 	%fd2, %fd31;
	setp.ge.f64	%p3, %fd2, 0d4330000000000000;
	@%p3 bra 	BB6_8;

	add.f64 	%fd22, %fd2, 0d3FE0000000000000;
	cvt.rzi.f64.f64	%fd23, %fd22;
	setp.lt.f64	%p4, %fd2, 0d3FE0000000000000;
	selp.f64	%fd24, 0d0000000000000000, %fd23, %p4;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r28, %temp}, %fd24;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r29}, %fd24;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r30}, %fd31;
	}
	and.b32  	%r31, %r30, -2147483648;
	or.b32  	%r32, %r29, %r31;
	mov.b64 	%fd31, {%r28, %r32};

BB6_8:
	cvt.rn.f64.s32	%fd25, %r3;
	fma.rn.f64 	%fd26, %fd25, 0d3FE0000000000000, %fd31;
	add.f64 	%fd27, %fd26, 0d3FF0000000000000;
	cvt.rzi.u64.f64	%rd25, %fd27;
	mul.lo.s32 	%r33, %r1, %r3;
	cvt.s64.s32	%rd26, %r33;
	add.s64 	%rd27, %rd25, %rd26;
	shl.b64 	%rd28, %rd27, 3;
	add.s64 	%rd29, %rd14, %rd28;
	shl.b64 	%rd30, %rd2, 3;
	add.s64 	%rd31, %rd15, %rd30;
	ld.volatile.global.f64 	%fd28, [%rd31];
	ld.global.f64 	%fd29, [%rd29];
	add.f64 	%fd30, %fd29, %fd28;
	st.volatile.global.f64 	[%rd31], %fd30;
	mov.u64 	%rd32, 0;
	st.global.u64 	[%rd31], %rd32;
	ret;
}

	// .globl	make_irr_field
.entry make_irr_field(
	.param .u32 make_irr_field_param_0,
	.param .u32 make_irr_field_param_1,
	.param .u64 .ptr .global .align 32 make_irr_field_param_2,
	.param .u64 .ptr .global .align 8 make_irr_field_param_3,
	.param .u64 .ptr .global .align 32 make_irr_field_param_4,
	.param .f64 make_irr_field_param_5
)
{
	.reg .pred 	%p<5>;
	.reg .b32 	%r<19>;
	.reg .f64 	%fd<44>;
	.reg .b64 	%rd<13>;


	ld.param.u32 	%r3, [make_irr_field_param_0];
	ld.param.u32 	%r4, [make_irr_field_param_1];
	ld.param.u64 	%rd2, [make_irr_field_param_2];
	ld.param.u64 	%rd3, [make_irr_field_param_3];
	ld.param.u64 	%rd4, [make_irr_field_param_4];
	ld.param.f64 	%fd16, [make_irr_field_param_5];
	mov.b32	%r5, %envreg3;
	mov.u32 	%r6, %ctaid.x;
	mov.u32 	%r7, %ntid.x;
	mad.lo.s32 	%r8, %r6, %r7, %r5;
	mov.u32 	%r9, %tid.x;
	add.s32 	%r10, %r8, %r9;
	mul.wide.s32 	%rd5, %r10, 32;
	add.s64 	%rd1, %rd4, %rd5;
	ld.global.v2.f64 	{%fd18, %fd19}, [%rd1+16];
	ld.global.v2.f64 	{%fd20, %fd21}, [%rd1];
	mov.f64 	%fd43, 0d0000000000000000;
	setp.lt.s32	%p1, %r3, 1;
	@%p1 bra 	BB7_5;

	cvt.rn.f64.s32	%fd8, %r4;
	mov.f64 	%fd43, 0d0000000000000000;
	mov.u32 	%r18, 0;

BB7_2:
	mul.wide.s32 	%rd6, %r18, 32;
	add.s64 	%rd7, %rd2, %rd6;
	ld.global.v2.f64 	{%fd23, %fd24}, [%rd7+16];
	ld.global.v2.f64 	{%fd25, %fd26}, [%rd7];
	mul.f64 	%fd29, %fd21, %fd26;
	fma.rn.f64 	%fd30, %fd20, %fd25, %fd29;
	fma.rn.f64 	%fd32, %fd18, %fd23, %fd30;
	fma.rn.f64 	%fd34, %fd24, 0d0000000000000000, %fd32;
	mul.f64 	%fd35, %fd34, %fd16;
	neg.f64 	%fd42, %fd35;
	abs.f64 	%fd11, %fd42;
	setp.ge.f64	%p2, %fd11, 0d4330000000000000;
	@%p2 bra 	BB7_4;

	add.f64 	%fd36, %fd11, 0d3FE0000000000000;
	cvt.rzi.f64.f64	%fd37, %fd36;
	setp.lt.f64	%p3, %fd11, 0d3FE0000000000000;
	selp.f64	%fd38, 0d0000000000000000, %fd37, %p3;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r12, %temp}, %fd38;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r13}, %fd38;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r14}, %fd42;
	}
	and.b32  	%r15, %r14, -2147483648;
	or.b32  	%r16, %r13, %r15;
	mov.b64 	%fd42, {%r12, %r16};

BB7_4:
	fma.rn.f64 	%fd39, %fd8, 0d3FE0000000000000, %fd42;
	add.f64 	%fd40, %fd39, 0d3FF0000000000000;
	cvt.rzi.u64.f64	%rd8, %fd40;
	mul.lo.s32 	%r17, %r18, %r4;
	cvt.s64.s32	%rd9, %r17;
	add.s64 	%rd10, %rd8, %rd9;
	shl.b64 	%rd11, %rd10, 3;
	add.s64 	%rd12, %rd3, %rd11;
	ld.global.f64 	%fd41, [%rd12];
	add.f64 	%fd43, %fd43, %fd41;
	add.s32 	%r18, %r18, 1;
	setp.lt.s32	%p4, %r18, %r3;
	@%p4 bra 	BB7_2;

BB7_5:
	st.global.v2.f64 	[%rd1], {%fd20, %fd21};
	st.global.v2.f64 	[%rd1+16], {%fd18, %fd43};
	ret;
}

	// .globl	make_irr_field_blocking
.entry make_irr_field_blocking(
	.param .u32 make_irr_field_blocking_param_0,
	.param .u32 make_irr_field_blocking_param_1,
	.param .u64 .ptr .global .align 32 make_irr_field_blocking_param_2,
	.param .u64 .ptr .global .align 8 make_irr_field_blocking_param_3,
	.param .u64 .ptr .global .align 32 make_irr_field_blocking_param_4,
	.param .f64 make_irr_field_blocking_param_5
)
{
	.reg .pred 	%p<7>;
	.reg .b32 	%r<31>;
	.reg .f64 	%fd<69>;
	.reg .b64 	%rd<19>;
	// demoted variable
	.shared .align 32 .b8 make_irr_field_blocking$loc_vecs[2048];

	ld.param.u32 	%r8, [make_irr_field_blocking_param_0];
	ld.param.u32 	%r9, [make_irr_field_blocking_param_1];
	ld.param.u64 	%rd2, [make_irr_field_blocking_param_2];
	ld.param.u64 	%rd3, [make_irr_field_blocking_param_3];
	ld.param.u64 	%rd4, [make_irr_field_blocking_param_4];
	ld.param.f64 	%fd26, [make_irr_field_blocking_param_5];
	mov.b32	%r10, %envreg3;
	mov.u32 	%r11, %ctaid.x;
	mov.u32 	%r12, %ntid.x;
	mad.lo.s32 	%r13, %r11, %r12, %r10;
	mov.u32 	%r14, %tid.x;
	add.s32 	%r15, %r13, %r14;
	mul.wide.s32 	%rd5, %r15, 32;
	add.s64 	%rd1, %rd4, %rd5;
	ld.global.v2.f64 	{%fd28, %fd29}, [%rd1+16];
	mov.f64 	%fd4, %fd29;
	mov.f64 	%fd67, %fd28;
	ld.global.v2.f64 	{%fd30, %fd31}, [%rd1];
	mov.f64 	%fd66, %fd31;
	mov.f64 	%fd65, %fd30;
	mov.f64 	%fd68, 0d0000000000000000;
	setp.lt.s32	%p1, %r8, 1;
	@%p1 bra 	BB8_8;

	cvt.rn.f64.s32	%fd8, %r9;
	mov.f64 	%fd68, 0d0000000000000000;
	mov.u32 	%r30, 0;

BB8_2:
	mov.u32 	%r29, %r30;
	add.s32 	%r18, %r29, %r14;
	mul.wide.s32 	%rd6, %r18, 32;
	add.s64 	%rd7, %rd2, %rd6;
	ld.global.v2.f64 	{%fd33, %fd34}, [%rd7];
	ld.global.v2.f64 	{%fd37, %fd38}, [%rd7+16];
	mul.wide.s32 	%rd8, %r14, 32;
	mov.u64 	%rd9, make_irr_field_blocking$loc_vecs;
	add.s64 	%rd10, %rd9, %rd8;
	st.shared.v2.f64 	[%rd10+16], {%fd37, %fd38};
	st.shared.v2.f64 	[%rd10], {%fd33, %fd34};
	bar.sync 	0;
	add.s32 	%r30, %r29, 64;
	min.s32 	%r2, %r8, %r30;
	mov.u32 	%r27, 0;
	setp.ge.s32	%p2, %r29, %r2;
	@%p2 bra 	BB8_6;

BB8_3:
	mul.wide.s32 	%rd11, %r27, 32;
	add.s64 	%rd13, %rd9, %rd11;
	ld.shared.v2.f64 	{%fd41, %fd42}, [%rd13+16];
	ld.shared.v2.f64 	{%fd43, %fd44}, [%rd13];
	mul.f64 	%fd47, %fd31, %fd44;
	fma.rn.f64 	%fd48, %fd30, %fd43, %fd47;
	fma.rn.f64 	%fd50, %fd28, %fd41, %fd48;
	fma.rn.f64 	%fd52, %fd42, 0d0000000000000000, %fd50;
	mul.f64 	%fd53, %fd52, %fd26;
	neg.f64 	%fd64, %fd53;
	abs.f64 	%fd12, %fd64;
	setp.ge.f64	%p3, %fd12, 0d4330000000000000;
	@%p3 bra 	BB8_5;

	add.f64 	%fd54, %fd12, 0d3FE0000000000000;
	cvt.rzi.f64.f64	%fd55, %fd54;
	setp.lt.f64	%p4, %fd12, 0d3FE0000000000000;
	selp.f64	%fd56, 0d0000000000000000, %fd55, %p4;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r21, %temp}, %fd56;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r22}, %fd56;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r23}, %fd64;
	}
	and.b32  	%r24, %r23, -2147483648;
	or.b32  	%r25, %r22, %r24;
	mov.b64 	%fd64, {%r21, %r25};

BB8_5:
	fma.rn.f64 	%fd57, %fd8, 0d3FE0000000000000, %fd64;
	add.f64 	%fd58, %fd57, 0d3FF0000000000000;
	cvt.rzi.u64.f64	%rd14, %fd58;
	mul.lo.s32 	%r26, %r29, %r9;
	cvt.s64.s32	%rd15, %r26;
	add.s64 	%rd16, %rd14, %rd15;
	shl.b64 	%rd17, %rd16, 3;
	add.s64 	%rd18, %rd3, %rd17;
	ld.global.f64 	%fd59, [%rd18];
	add.f64 	%fd68, %fd68, %fd59;
	add.s32 	%r27, %r27, 1;
	add.s32 	%r29, %r29, 1;
	setp.lt.s32	%p5, %r29, %r2;
	@%p5 bra 	BB8_3;

BB8_6:
	bar.sync 	0;
	setp.lt.s32	%p6, %r30, %r8;
	@%p6 bra 	BB8_2;

	ld.global.v2.f64 	{%fd60, %fd61}, [%rd1+16];
	mov.f64 	%fd20, %fd61;
	mov.f64 	%fd67, %fd60;
	ld.global.v2.f64 	{%fd62, %fd63}, [%rd1];
	mov.f64 	%fd66, %fd63;
	mov.f64 	%fd65, %fd62;

BB8_8:
	st.global.v2.f64 	[%rd1], {%fd65, %fd66};
	st.global.v2.f64 	[%rd1+16], {%fd67, %fd68};
	ret;
}

	// .globl	make_irr_field_unroll
.entry make_irr_field_unroll(
	.param .u32 make_irr_field_unroll_param_0,
	.param .u32 make_irr_field_unroll_param_1,
	.param .u64 .ptr .global .align 32 make_irr_field_unroll_param_2,
	.param .u64 .ptr .global .align 8 make_irr_field_unroll_param_3,
	.param .u64 .ptr .global .align 32 make_irr_field_unroll_param_4,
	.param .f64 make_irr_field_unroll_param_5
)
{
	.reg .pred 	%p<11>;
	.reg .b32 	%r<40>;
	.reg .f64 	%fd<117>;
	.reg .b64 	%rd<29>;


	ld.param.u32 	%r3, [make_irr_field_unroll_param_0];
	ld.param.u32 	%r4, [make_irr_field_unroll_param_1];
	ld.param.u64 	%rd4, [make_irr_field_unroll_param_2];
	ld.param.u64 	%rd5, [make_irr_field_unroll_param_3];
	ld.param.u64 	%rd6, [make_irr_field_unroll_param_4];
	ld.param.f64 	%fd29, [make_irr_field_unroll_param_5];
	mov.b32	%r5, %envreg3;
	mov.u32 	%r6, %ctaid.x;
	mov.u32 	%r7, %ntid.x;
	mad.lo.s32 	%r8, %r6, %r7, %r5;
	mov.u32 	%r9, %tid.x;
	add.s32 	%r10, %r8, %r9;
	mul.wide.s32 	%rd7, %r10, 32;
	add.s64 	%rd1, %rd6, %rd7;
	ld.global.v2.f64 	{%fd31, %fd32}, [%rd1+16];
	ld.global.v2.f64 	{%fd33, %fd34}, [%rd1];
	mov.f64 	%fd116, 0d0000000000000000;
	setp.lt.s32	%p1, %r3, 1;
	@%p1 bra 	BB9_11;

	cvt.rn.f64.s32	%fd6, %r4;
	mov.f64 	%fd116, 0d0000000000000000;
	mov.u32 	%r39, 0;

BB9_2:
	mul.wide.s32 	%rd8, %r39, 32;
	add.s64 	%rd2, %rd4, %rd8;
	ld.global.v2.f64 	{%fd36, %fd37}, [%rd2+16];
	ld.global.v2.f64 	{%fd38, %fd39}, [%rd2];
	mul.f64 	%fd42, %fd34, %fd39;
	fma.rn.f64 	%fd43, %fd33, %fd38, %fd42;
	fma.rn.f64 	%fd45, %fd31, %fd36, %fd43;
	fma.rn.f64 	%fd47, %fd37, 0d0000000000000000, %fd45;
	mul.f64 	%fd48, %fd47, %fd29;
	neg.f64 	%fd112, %fd48;
	abs.f64 	%fd9, %fd112;
	setp.ge.f64	%p2, %fd9, 0d4330000000000000;
	@%p2 bra 	BB9_4;

	add.f64 	%fd49, %fd9, 0d3FE0000000000000;
	cvt.rzi.f64.f64	%fd50, %fd49;
	setp.lt.f64	%p3, %fd9, 0d3FE0000000000000;
	selp.f64	%fd51, 0d0000000000000000, %fd50, %p3;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r12, %temp}, %fd51;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r13}, %fd51;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r14}, %fd112;
	}
	and.b32  	%r15, %r14, -2147483648;
	or.b32  	%r16, %r13, %r15;
	mov.b64 	%fd112, {%r12, %r16};

BB9_4:
	fma.rn.f64 	%fd52, %fd6, 0d3FE0000000000000, %fd112;
	add.f64 	%fd53, %fd52, 0d3FF0000000000000;
	cvt.rzi.u64.f64	%rd9, %fd53;
	mul.lo.s32 	%r17, %r39, %r4;
	cvt.s64.s32	%rd10, %r17;
	add.s64 	%rd11, %rd9, %rd10;
	shl.b64 	%rd12, %rd11, 3;
	add.s64 	%rd13, %rd5, %rd12;
	ld.global.f64 	%fd54, [%rd13];
	add.f64 	%fd12, %fd116, %fd54;
	ld.global.v2.f64 	{%fd55, %fd56}, [%rd2+48];
	ld.global.v2.f64 	{%fd57, %fd58}, [%rd2+32];
	mul.f64 	%fd61, %fd34, %fd58;
	fma.rn.f64 	%fd62, %fd33, %fd57, %fd61;
	fma.rn.f64 	%fd64, %fd31, %fd55, %fd62;
	fma.rn.f64 	%fd66, %fd56, 0d0000000000000000, %fd64;
	mul.f64 	%fd67, %fd66, %fd29;
	neg.f64 	%fd113, %fd67;
	abs.f64 	%fd14, %fd113;
	setp.ge.f64	%p4, %fd14, 0d4330000000000000;
	@%p4 bra 	BB9_6;

	add.f64 	%fd68, %fd14, 0d3FE0000000000000;
	cvt.rzi.f64.f64	%fd69, %fd68;
	setp.lt.f64	%p5, %fd14, 0d3FE0000000000000;
	selp.f64	%fd70, 0d0000000000000000, %fd69, %p5;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r18, %temp}, %fd70;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r19}, %fd70;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r20}, %fd113;
	}
	and.b32  	%r21, %r20, -2147483648;
	or.b32  	%r22, %r19, %r21;
	mov.b64 	%fd113, {%r18, %r22};

BB9_6:
	add.s32 	%r23, %r39, 1;
	fma.rn.f64 	%fd71, %fd6, 0d3FE0000000000000, %fd113;
	add.f64 	%fd72, %fd71, 0d3FF0000000000000;
	cvt.rzi.u64.f64	%rd14, %fd72;
	mul.lo.s32 	%r24, %r23, %r4;
	cvt.s64.s32	%rd15, %r24;
	add.s64 	%rd16, %rd14, %rd15;
	shl.b64 	%rd17, %rd16, 3;
	add.s64 	%rd18, %rd5, %rd17;
	ld.global.f64 	%fd73, [%rd18];
	add.f64 	%fd17, %fd12, %fd73;
	ld.global.v2.f64 	{%fd74, %fd75}, [%rd2+80];
	ld.global.v2.f64 	{%fd76, %fd77}, [%rd2+64];
	mul.f64 	%fd80, %fd34, %fd77;
	fma.rn.f64 	%fd81, %fd33, %fd76, %fd80;
	fma.rn.f64 	%fd83, %fd31, %fd74, %fd81;
	fma.rn.f64 	%fd85, %fd75, 0d0000000000000000, %fd83;
	mul.f64 	%fd86, %fd85, %fd29;
	neg.f64 	%fd114, %fd86;
	abs.f64 	%fd19, %fd114;
	setp.ge.f64	%p6, %fd19, 0d4330000000000000;
	@%p6 bra 	BB9_8;

	add.f64 	%fd87, %fd19, 0d3FE0000000000000;
	cvt.rzi.f64.f64	%fd88, %fd87;
	setp.lt.f64	%p7, %fd19, 0d3FE0000000000000;
	selp.f64	%fd89, 0d0000000000000000, %fd88, %p7;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r25, %temp}, %fd89;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r26}, %fd89;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r27}, %fd114;
	}
	and.b32  	%r28, %r27, -2147483648;
	or.b32  	%r29, %r26, %r28;
	mov.b64 	%fd114, {%r25, %r29};

BB9_8:
	add.s32 	%r30, %r39, 2;
	fma.rn.f64 	%fd90, %fd6, 0d3FE0000000000000, %fd114;
	add.f64 	%fd91, %fd90, 0d3FF0000000000000;
	cvt.rzi.u64.f64	%rd19, %fd91;
	mul.lo.s32 	%r31, %r30, %r4;
	cvt.s64.s32	%rd20, %r31;
	add.s64 	%rd21, %rd19, %rd20;
	shl.b64 	%rd22, %rd21, 3;
	add.s64 	%rd23, %rd5, %rd22;
	ld.global.f64 	%fd92, [%rd23];
	add.f64 	%fd22, %fd17, %fd92;
	ld.global.v2.f64 	{%fd93, %fd94}, [%rd2+112];
	ld.global.v2.f64 	{%fd95, %fd96}, [%rd2+96];
	mul.f64 	%fd99, %fd34, %fd96;
	fma.rn.f64 	%fd100, %fd33, %fd95, %fd99;
	fma.rn.f64 	%fd102, %fd31, %fd93, %fd100;
	fma.rn.f64 	%fd104, %fd94, 0d0000000000000000, %fd102;
	mul.f64 	%fd105, %fd104, %fd29;
	neg.f64 	%fd115, %fd105;
	abs.f64 	%fd24, %fd115;
	setp.ge.f64	%p8, %fd24, 0d4330000000000000;
	@%p8 bra 	BB9_10;

	add.f64 	%fd106, %fd24, 0d3FE0000000000000;
	cvt.rzi.f64.f64	%fd107, %fd106;
	setp.lt.f64	%p9, %fd24, 0d3FE0000000000000;
	selp.f64	%fd108, 0d0000000000000000, %fd107, %p9;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r32, %temp}, %fd108;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r33}, %fd108;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r34}, %fd115;
	}
	and.b32  	%r35, %r34, -2147483648;
	or.b32  	%r36, %r33, %r35;
	mov.b64 	%fd115, {%r32, %r36};

BB9_10:
	add.s32 	%r37, %r39, 3;
	fma.rn.f64 	%fd109, %fd6, 0d3FE0000000000000, %fd115;
	add.f64 	%fd110, %fd109, 0d3FF0000000000000;
	cvt.rzi.u64.f64	%rd24, %fd110;
	mul.lo.s32 	%r38, %r37, %r4;
	cvt.s64.s32	%rd25, %r38;
	add.s64 	%rd26, %rd24, %rd25;
	shl.b64 	%rd27, %rd26, 3;
	add.s64 	%rd28, %rd5, %rd27;
	ld.global.f64 	%fd111, [%rd28];
	add.f64 	%fd116, %fd22, %fd111;
	add.s32 	%r39, %r39, 4;
	setp.lt.s32	%p10, %r39, %r3;
	@%p10 bra 	BB9_2;

BB9_11:
	st.global.v2.f64 	[%rd1], {%fd33, %fd34};
	st.global.v2.f64 	[%rd1+16], {%fd31, %fd116};
	ret;
}

	// .globl	make_irr_field_blocking_unroll
.entry make_irr_field_blocking_unroll(
	.param .u32 make_irr_field_blocking_unroll_param_0,
	.param .u32 make_irr_field_blocking_unroll_param_1,
	.param .u64 .ptr .global .align 32 make_irr_field_blocking_unroll_param_2,
	.param .u64 .ptr .global .align 8 make_irr_field_blocking_unroll_param_3,
	.param .u64 .ptr .global .align 32 make_irr_field_blocking_unroll_param_4,
	.param .f64 make_irr_field_blocking_unroll_param_5
)
{
	.reg .pred 	%p<13>;
	.reg .b32 	%r<52>;
	.reg .f64 	%fd<144>;
	.reg .b64 	%rd<35>;
	// demoted variable
	.shared .align 32 .b8 make_irr_field_blocking_unroll$loc_vecs[2048];

	ld.param.u32 	%r8, [make_irr_field_blocking_unroll_param_0];
	ld.param.u32 	%r9, [make_irr_field_blocking_unroll_param_1];
	ld.param.u64 	%rd4, [make_irr_field_blocking_unroll_param_2];
	ld.param.u64 	%rd5, [make_irr_field_blocking_unroll_param_3];
	ld.param.u64 	%rd6, [make_irr_field_blocking_unroll_param_4];
	ld.param.f64 	%fd41, [make_irr_field_blocking_unroll_param_5];
	mov.b32	%r10, %envreg3;
	mov.u32 	%r11, %ctaid.x;
	mov.u32 	%r12, %ntid.x;
	mad.lo.s32 	%r13, %r11, %r12, %r10;
	mov.u32 	%r14, %tid.x;
	add.s32 	%r15, %r13, %r14;
	mul.wide.s32 	%rd7, %r15, 32;
	add.s64 	%rd1, %rd6, %rd7;
	ld.global.v2.f64 	{%fd43, %fd44}, [%rd1+16];
	mov.f64 	%fd4, %fd44;
	mov.f64 	%fd142, %fd43;
	ld.global.v2.f64 	{%fd45, %fd46}, [%rd1];
	mov.f64 	%fd141, %fd46;
	mov.f64 	%fd140, %fd45;
	mov.f64 	%fd143, 0d0000000000000000;
	setp.lt.s32	%p1, %r8, 1;
	@%p1 bra 	BB10_14;

	cvt.rn.f64.s32	%fd8, %r9;
	mov.f64 	%fd143, 0d0000000000000000;
	mov.u32 	%r51, 0;

BB10_2:
	mov.u32 	%r50, %r51;
	add.s32 	%r18, %r50, %r14;
	mul.wide.s32 	%rd8, %r18, 32;
	add.s64 	%rd9, %rd4, %rd8;
	ld.global.v2.f64 	{%fd48, %fd49}, [%rd9];
	ld.global.v2.f64 	{%fd52, %fd53}, [%rd9+16];
	mul.wide.s32 	%rd10, %r14, 32;
	mov.u64 	%rd11, make_irr_field_blocking_unroll$loc_vecs;
	add.s64 	%rd12, %rd11, %rd10;
	st.shared.v2.f64 	[%rd12+16], {%fd52, %fd53};
	st.shared.v2.f64 	[%rd12], {%fd48, %fd49};
	bar.sync 	0;
	add.s32 	%r51, %r50, 64;
	min.s32 	%r2, %r8, %r51;
	mov.u32 	%r48, 0;
	setp.ge.s32	%p2, %r50, %r2;
	@%p2 bra 	BB10_12;

BB10_3:
	mul.wide.s32 	%rd13, %r48, 32;
	add.s64 	%rd2, %rd11, %rd13;
	ld.shared.v2.f64 	{%fd56, %fd57}, [%rd2+16];
	ld.shared.v2.f64 	{%fd58, %fd59}, [%rd2];
	mul.f64 	%fd62, %fd46, %fd59;
	fma.rn.f64 	%fd63, %fd45, %fd58, %fd62;
	fma.rn.f64 	%fd65, %fd43, %fd56, %fd63;
	fma.rn.f64 	%fd67, %fd57, 0d0000000000000000, %fd65;
	mul.f64 	%fd68, %fd67, %fd41;
	neg.f64 	%fd136, %fd68;
	abs.f64 	%fd12, %fd136;
	setp.ge.f64	%p3, %fd12, 0d4330000000000000;
	@%p3 bra 	BB10_5;

	add.f64 	%fd69, %fd12, 0d3FE0000000000000;
	cvt.rzi.f64.f64	%fd70, %fd69;
	setp.lt.f64	%p4, %fd12, 0d3FE0000000000000;
	selp.f64	%fd71, 0d0000000000000000, %fd70, %p4;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r21, %temp}, %fd71;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r22}, %fd71;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r23}, %fd136;
	}
	and.b32  	%r24, %r23, -2147483648;
	or.b32  	%r25, %r22, %r24;
	mov.b64 	%fd136, {%r21, %r25};

BB10_5:
	fma.rn.f64 	%fd72, %fd8, 0d3FE0000000000000, %fd136;
	add.f64 	%fd73, %fd72, 0d3FF0000000000000;
	cvt.rzi.u64.f64	%rd15, %fd73;
	mul.lo.s32 	%r26, %r50, %r9;
	cvt.s64.s32	%rd16, %r26;
	add.s64 	%rd17, %rd15, %rd16;
	shl.b64 	%rd18, %rd17, 3;
	add.s64 	%rd19, %rd5, %rd18;
	ld.global.f64 	%fd74, [%rd19];
	add.f64 	%fd15, %fd143, %fd74;
	ld.shared.v2.f64 	{%fd75, %fd76}, [%rd2+48];
	ld.shared.v2.f64 	{%fd77, %fd78}, [%rd2+32];
	mul.f64 	%fd81, %fd46, %fd78;
	fma.rn.f64 	%fd82, %fd45, %fd77, %fd81;
	fma.rn.f64 	%fd84, %fd43, %fd75, %fd82;
	fma.rn.f64 	%fd86, %fd76, 0d0000000000000000, %fd84;
	mul.f64 	%fd87, %fd86, %fd41;
	neg.f64 	%fd137, %fd87;
	abs.f64 	%fd17, %fd137;
	setp.ge.f64	%p5, %fd17, 0d4330000000000000;
	@%p5 bra 	BB10_7;

	add.f64 	%fd88, %fd17, 0d3FE0000000000000;
	cvt.rzi.f64.f64	%fd89, %fd88;
	setp.lt.f64	%p6, %fd17, 0d3FE0000000000000;
	selp.f64	%fd90, 0d0000000000000000, %fd89, %p6;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r27, %temp}, %fd90;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r28}, %fd90;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r29}, %fd137;
	}
	and.b32  	%r30, %r29, -2147483648;
	or.b32  	%r31, %r28, %r30;
	mov.b64 	%fd137, {%r27, %r31};

BB10_7:
	fma.rn.f64 	%fd91, %fd8, 0d3FE0000000000000, %fd137;
	add.f64 	%fd92, %fd91, 0d3FF0000000000000;
	cvt.rzi.u64.f64	%rd20, %fd92;
	add.s32 	%r32, %r50, 1;
	mul.lo.s32 	%r33, %r32, %r9;
	cvt.s64.s32	%rd21, %r33;
	add.s64 	%rd22, %rd20, %rd21;
	shl.b64 	%rd23, %rd22, 3;
	add.s64 	%rd24, %rd5, %rd23;
	ld.global.f64 	%fd93, [%rd24];
	add.f64 	%fd20, %fd15, %fd93;
	ld.shared.v2.f64 	{%fd94, %fd95}, [%rd2+80];
	ld.shared.v2.f64 	{%fd96, %fd97}, [%rd2+64];
	mul.f64 	%fd100, %fd46, %fd97;
	fma.rn.f64 	%fd101, %fd45, %fd96, %fd100;
	fma.rn.f64 	%fd103, %fd43, %fd94, %fd101;
	fma.rn.f64 	%fd105, %fd95, 0d0000000000000000, %fd103;
	mul.f64 	%fd106, %fd105, %fd41;
	neg.f64 	%fd138, %fd106;
	abs.f64 	%fd22, %fd138;
	setp.ge.f64	%p7, %fd22, 0d4330000000000000;
	@%p7 bra 	BB10_9;

	add.f64 	%fd107, %fd22, 0d3FE0000000000000;
	cvt.rzi.f64.f64	%fd108, %fd107;
	setp.lt.f64	%p8, %fd22, 0d3FE0000000000000;
	selp.f64	%fd109, 0d0000000000000000, %fd108, %p8;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r34, %temp}, %fd109;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r35}, %fd109;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r36}, %fd138;
	}
	and.b32  	%r37, %r36, -2147483648;
	or.b32  	%r38, %r35, %r37;
	mov.b64 	%fd138, {%r34, %r38};

BB10_9:
	fma.rn.f64 	%fd110, %fd8, 0d3FE0000000000000, %fd138;
	add.f64 	%fd111, %fd110, 0d3FF0000000000000;
	cvt.rzi.u64.f64	%rd25, %fd111;
	add.s32 	%r39, %r50, 2;
	mul.lo.s32 	%r40, %r39, %r9;
	cvt.s64.s32	%rd26, %r40;
	add.s64 	%rd27, %rd25, %rd26;
	shl.b64 	%rd28, %rd27, 3;
	add.s64 	%rd29, %rd5, %rd28;
	ld.global.f64 	%fd112, [%rd29];
	add.f64 	%fd25, %fd20, %fd112;
	ld.shared.v2.f64 	{%fd113, %fd114}, [%rd2+112];
	ld.shared.v2.f64 	{%fd115, %fd116}, [%rd2+96];
	mul.f64 	%fd119, %fd46, %fd116;
	fma.rn.f64 	%fd120, %fd45, %fd115, %fd119;
	fma.rn.f64 	%fd122, %fd43, %fd113, %fd120;
	fma.rn.f64 	%fd124, %fd114, 0d0000000000000000, %fd122;
	mul.f64 	%fd125, %fd124, %fd41;
	neg.f64 	%fd139, %fd125;
	abs.f64 	%fd27, %fd139;
	setp.ge.f64	%p9, %fd27, 0d4330000000000000;
	@%p9 bra 	BB10_11;

	add.f64 	%fd126, %fd27, 0d3FE0000000000000;
	cvt.rzi.f64.f64	%fd127, %fd126;
	setp.lt.f64	%p10, %fd27, 0d3FE0000000000000;
	selp.f64	%fd128, 0d0000000000000000, %fd127, %p10;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r41, %temp}, %fd128;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r42}, %fd128;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r43}, %fd139;
	}
	and.b32  	%r44, %r43, -2147483648;
	or.b32  	%r45, %r42, %r44;
	mov.b64 	%fd139, {%r41, %r45};

BB10_11:
	fma.rn.f64 	%fd129, %fd8, 0d3FE0000000000000, %fd139;
	add.f64 	%fd130, %fd129, 0d3FF0000000000000;
	cvt.rzi.u64.f64	%rd30, %fd130;
	add.s32 	%r46, %r50, 3;
	mul.lo.s32 	%r47, %r46, %r9;
	cvt.s64.s32	%rd31, %r47;
	add.s64 	%rd32, %rd30, %rd31;
	shl.b64 	%rd33, %rd32, 3;
	add.s64 	%rd34, %rd5, %rd33;
	ld.global.f64 	%fd131, [%rd34];
	add.f64 	%fd143, %fd25, %fd131;
	bar.sync 	0;
	add.s32 	%r48, %r48, 4;
	add.s32 	%r50, %r50, 4;
	setp.lt.s32	%p11, %r50, %r2;
	@%p11 bra 	BB10_3;

BB10_12:
	setp.lt.s32	%p12, %r51, %r8;
	@%p12 bra 	BB10_2;

	ld.global.v2.f64 	{%fd132, %fd133}, [%rd1+16];
	mov.f64 	%fd35, %fd133;
	mov.f64 	%fd142, %fd132;
	ld.global.v2.f64 	{%fd134, %fd135}, [%rd1];
	mov.f64 	%fd141, %fd135;
	mov.f64 	%fd140, %fd134;

BB10_14:
	st.global.v2.f64 	[%rd1], {%fd140, %fd141};
	st.global.v2.f64 	[%rd1+16], {%fd142, %fd143};
	ret;
}


  